{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "sFCCB6kmBTIX",
      "metadata": {
        "id": "sFCCB6kmBTIX"
      },
      "source": [
        "In this demo Iâ€™m going to show you three things:\n",
        "\n",
        "1. A no code way to create a data store tool that can be used to perform Retrieval Augmented Generation\n",
        "2. A low code way to create a conversational agent using Agent Builder\n",
        "3. A code-first way to create a workflow agent"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4im6XDEPBjY2",
      "metadata": {
        "id": "4im6XDEPBjY2"
      },
      "source": [
        "# No Code Data Store Tool"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fHQdTYCVDqqy",
      "metadata": {
        "id": "fHQdTYCVDqqy"
      },
      "source": [
        "**Pros:**\n",
        "* Managed runtime\n",
        "* UI based\n",
        "* No code involved in making the tool\n",
        "\n",
        "**Cons:**\n",
        "* Less control due to managed runtime (still fits most conversational use cases and some non-conversational use cases)\n",
        "\n",
        "#### Steps\n",
        "1. Create a Cloud Storage bucket and upload the [Cymbal Starlight PDF](https://github.com/GoogleCloudPlatform/generative-ai/blob/main/gemini/sample-apps/fixmycar/manuals/cymbal-starlight-2024.pdf)\n",
        "2. In the Google Cloud console, go to Agent Builder\n",
        "3. Create a new app\n",
        "4. Under `Search for your website` click on **Create**\n",
        "5. Fill in `App name` and and `Company name` and click **CONTINUE**\n",
        "6. Click **CREATE DATA STORE**\n",
        "7. Under `Cloud Storage` click **SELECT**\n",
        "8. Under `Select a folder or a file you want to import` click **BROWSE** and upload the PDF and click **CONTINUE**\n",
        "9. Name your datastore `car_manuals` and click **CREATE**\n",
        "10. Click **CREATE** again\n",
        "11. Click on the **Activity** tab and wait until the import process completes\n",
        "12. Click on **Preview** and search `How do I use cruise control?`\n",
        "13. Click on **Integration** and the **API** tab\n",
        "14. Under **Search query**, enter `How do I use cruise control?` and click **RUN IN CLOUD SHELL**. Notice how it gives you the same output.\n",
        "15. Check out the other customizations you can use when calling the API [here](https://cloud.google.com/generative-ai-app-builder/docs/preview-search-results?authuser=3). For example, you can use `RESULT_MODE` to return chunks of text instead of documents. This could be useful to an agent that is trying to reason about how to handle the returned results."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "siqvqavCTpHJ",
      "metadata": {
        "id": "siqvqavCTpHJ"
      },
      "source": [
        "## Low Code Conversational Agent"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "oOtLeDEHTwxC",
      "metadata": {
        "id": "oOtLeDEHTwxC"
      },
      "source": [
        "**Pros:**\n",
        "* Managed runtime\n",
        "* UI based\n",
        "\n",
        "**Cons:**\n",
        "* Less control due to managed runtime (still fits most conversational use cases and some non-conversational use cases)\n",
        "* You need to make the tool (although this might be inevitable depending on your use case)\n",
        "\n",
        "#### Steps\n",
        "1. Follow [this guide](https://github.com/willisc7/agent-builder-for-all) to deploy the Places service API, which will be used later\n",
        "1. Create a Cloud Storage bucket and upload the Cymbal Starlight PDF\n",
        "2. In the Google Cloud console, go to Agent Builder\n",
        "3. Create a new app\n",
        "4. Under `Conversation agents > Conversational agent` click on **Create** (dont select the Chat option)\n",
        "5. Click **Build Your Own**\n",
        "6. Type in \"Cymbal Agent\" and click **Create**\n",
        "7. Click on **Toggle Simulator** in the top right, select Gemini Flash as the model, and ask \"What do you know about the Tesla Model X?\" It should respond with whatever knowledge the base model has on the Model X.\n",
        "8. Lets improve the conversational agent a little. Configure the following under **Goal** in the lefthand pane:\n",
        "```\n",
        "You are a friendly Tesla service center agent.\n",
        "Your job is to answer questions about Tesla products.\n",
        "```\n",
        "9. Under **Instructions** put the following:\n",
        "```\n",
        "- Greet the user and answer their questions to the best of your knowledge\n",
        "- If the user asks about a Tesla service center location, do not provide information unless you are certain that you know the address.\n",
        "```\n",
        "10. Now chat with the bot again and say:\n",
        "```\n",
        "Where can I test drive a Model X in San Diego?\n",
        "```\n",
        "It will say it doesnt have the information.\n",
        "11. We need a tool to be able to get Tesla Service Center locations. So click on **Tools** on the lefthand pane\n",
        "12. Click **+Create**\n",
        "13. Under **Tool name** type in `places_search_tool`\n",
        "14. Under **Description** type in\n",
        "```\n",
        "A Places Search API that provides information on points of interest a city.\n",
        "```\n",
        "15. Under Schema, make sure its set to YAML and paste in the following (make sure to change the url to point to your cloud run service)\n",
        "```\n",
        "openapi: 3.0.2\n",
        "info:\n",
        "  title: Search API\n",
        "  description: >-\n",
        "    This API takes a search query and returns results\n",
        "  version: 2.0\n",
        "servers:\n",
        "  - url: <YOUR_CLOUD_RUN_ENDPOINT>\n",
        "paths:\n",
        "  /places_search_tool:\n",
        "    post:\n",
        "      summary: Retrieves points of interest for a location\n",
        "      operationId: places_search_tool\n",
        "      requestBody:\n",
        "        description: Query\n",
        "        content:\n",
        "          application/json:\n",
        "            schema:\n",
        "              $ref: '#/components/schemas/SearchInput'\n",
        "      responses:\n",
        "        '200':\n",
        "          description: Successfully got results (may be empty)\n",
        "          content:\n",
        "            application/json:\n",
        "              schema:\n",
        "                type: object\n",
        "                properties:\n",
        "                  results:\n",
        "                    type: array\n",
        "                    items:\n",
        "                        type: object\n",
        "                        properties:\n",
        "                            name:\n",
        "                                type: string\n",
        "components:\n",
        "  schemas:\n",
        "    SearchInput:\n",
        "      type: object\n",
        "      properties:\n",
        "        preferences:\n",
        "            type: string\n",
        "        city:\n",
        "            type: string\n",
        "```\n",
        "16. Click **Save**\n",
        "17. Go back to the agent playbook and change the instructions to:\n",
        "```\n",
        "- Greet the user and answer their questions to the best of your knowledge\n",
        "- If the user asks about a Tesla service center location, use the ${TOOL: places_search} to answer their question.\n",
        "```\n",
        "18. Click **Save**, restart the conversation, and ask \"Tell me about the new Model X\" and then say \"Where can I test drive a Model X in San Diego?\"\n",
        "19. Click on **Default Playbook** under Agent Invocations in the middle of the screen. It will select the full conversation. Click **Save example** and name it `example_1`\n",
        "20. Change the format of the conversation to something you prefer. Make sure you copy over the response body for the places_search_tool and click **Create**\n",
        "21. Go back to the conversation and reset it and ask \"Where can I test drive a model x in San Diego?\" and youll notice it will use the formatting you trained it to use.\n",
        "22. Follow up with \"What about Austin, TX?\" and itll use the context of the conversation to supply a similar answer"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "JZ8O3DfB4I5m",
      "metadata": {
        "id": "JZ8O3DfB4I5m"
      },
      "source": [
        "### Medium-High Code Agent"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1qanqLNF4Ut_",
      "metadata": {
        "id": "1qanqLNF4Ut_"
      },
      "source": [
        "**Pros:**\n",
        "* Full control as a developer\n",
        "\n",
        "**Cons:**\n",
        "* Steep learning curve\n",
        "* No managed runtime (you need to figure out how to deploy and host)\n",
        "\n",
        "#### Steps\n",
        "[This notebook](https://www.kaggle.com/code/markishere/day-3-building-an-agent-with-langgraph) provides a fantastic overview of how to build a conversational agent using LangGraph. Just in case that link becomes broken in the future, I've included a backup of the notebook in this repo as `building-an-agent-with-langgraph.ipynb`"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "Gen AI Agents Demo Script - San Diego DevFest 2024",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
